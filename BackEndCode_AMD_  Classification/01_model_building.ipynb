{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0bdda7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "get_ipython().run_line_magic('matplotlib', 'inline') ###\n",
    "################################################################################\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "################################################################################\n",
    "from keras import layers,utils\n",
    "from keras.datasets import cifar100\n",
    "from keras.models import Sequential,load_model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Dense, Dropout, Activation, Flatten,Conv2D,MaxPooling2D, MaxPool2D,Add, concatenate\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,LeakyReLU, Dense, InputLayer,Dropout, Activation, Flatten,Input, BatchNormalization, Conv2D, MaxPool2D, GlobalMaxPool2D,GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import VGG16, MobileNet, ResNet50, InceptionV3, Xception, VGG19,ResNet101\n",
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "################################################################################\n",
    "import gc\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7568d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global_Variables\n",
    "inputs = Input(shape=(448, 448, 3))\n",
    "sa_model_path = './models/MSE_MSLE_model001.h5'\n",
    "pretrained_model = ResNet50(input_shape=(224, 224, 3),weights='imagenet', include_top=False)\n",
    "final_model_name = 'Final_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf42655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some defined Loss Functions used by the Scale Adaptive model (Encoder model)\n",
    "def rmse(y_true, y_pred):\n",
    "  return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def custom_metric_SSIM_(y_true, y_pred):\n",
    "        x=y_true\n",
    "        y=y_pred\n",
    "        mean_x=tf.math.reduce_mean(x)\n",
    "        mean_y=tf.math.reduce_mean(y)\n",
    "\n",
    "        var_x=tf.math.reduce_variance(x)\n",
    "        var_y=tf.math.reduce_variance(y)\n",
    "        covar_xy=tfp.stats.covariance(x,y)\n",
    "\n",
    "        k1=0.01\n",
    "        k2=0.03\n",
    "        l=float(tf.math.pow(2,20) - 1)\n",
    "        c1=float(k1 * l)\n",
    "        c2=float(k2 * l)\n",
    "        print(type(c1))\n",
    "        c1 = tf.math.square(c1)\n",
    "        c2 = tf.math.square(c2)\n",
    "      # SSIM=(2μxμy + c1)(2σxy +c2)/((μx)2+(μy)2 +c1)((σx)2 +(σy)2 + c2)\n",
    "        m=tf.math.multiply(2.0,covar_xy)\n",
    "        t1=tf.math.add(m , c2)\n",
    "        m=tf.math.multiply(mean_x,mean_y)\n",
    "        m=float(m * 2.0)\n",
    "        t2=tf.math.add(m ,c1)\n",
    "        t3=(tf.math.square(mean_x)+tf.math.square(mean_y) +c1)\n",
    "        t4=(tf.math.square(var_x) +tf.math.square(var_y) + c2)\n",
    "\n",
    "        SSIM=tf.math.divide(tf.math.multiply(t2,t1),tf.math.multiply(t3,t4))\n",
    "        return tf.math.reduce_mean(SSIM)\n",
    "\n",
    "def custom_loss_MSEhigh_MSLElow_(y, y_pred):\n",
    "        l1=tf.keras.losses.MeanSquaredError()\n",
    "        l_high=l1(y[:,:,:,:12],y_pred[:,:,:,:12])\n",
    "\n",
    "        l2=tf.keras.losses.MeanSquaredLogarithmicError()\n",
    "        l_low=l2(y[:,:,:,12:],y_pred[:,:,:,12:])\n",
    "\n",
    "        return 0.4 * l_high + 0.6 * l_low\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e54b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the encoder model or Scale Adaptive model\n",
    "def load_encoder_model(model_path , inputs):\n",
    "    try:\n",
    "        resized_model = tf.keras.models.load_model(\n",
    "            model_path,\n",
    "            custom_objects={\"custom_metric_SSIM_\":custom_metric_SSIM_,\n",
    "                            \"custom_loss_MSEhigh_MSLElow_\":custom_loss_MSEhigh_MSLElow_,\n",
    "                            \"rmse\":rmse},\n",
    "            compile=False)\n",
    "        resized_model.trainable = False\n",
    "        print(f\"(✔) Model with name of '{model_path.split('/')[-1]}' is Successfuly Loaded....\")\n",
    "    except:\n",
    "        print(f'(X) Cannot find the model in this path {model_path}')\n",
    "        return None\n",
    "    return resized_model(inputs) \n",
    "\n",
    "# Function to join the pretrained_model with the Scale Adaptive model for feature extraction\n",
    "def build_feature_extractor_model(inputs , pretrained_model):\n",
    "    # inputs here is the Scale Adaptive model\n",
    "    try:\n",
    "        feature_extractor_model = pretrained_model\n",
    "        for layer in feature_extractor_model.layers:\n",
    "            layer.trainable = True\n",
    "        print(f\"(✔) Successfully loaded the pretrained model for transfer learning and combine with the Scale Adaptive model.....\")\n",
    "    except:\n",
    "        print(f'(X) Error while loading the pretrained model....')\n",
    "        return None\n",
    "    return feature_extractor_model(inputs)\n",
    "\n",
    "# Function to attach the classification layers to classify our data\n",
    "def attach_classifier(inputs):\n",
    "    # inputs here is the feature extractor model which is (SA+ResNET50) so far\n",
    "    try:\n",
    "        X = GlobalAveragePooling2D()(inputs)\n",
    "        X = Flatten()(X)\n",
    "\n",
    "        X = Dense(units=512, activation='relu')(X)\n",
    "        X = BatchNormalization()(X)\n",
    "        X = Dropout(0.2)(X)\n",
    "\n",
    "        X = Dense(units=256, activation='relu')(X)\n",
    "        X = BatchNormalization()(X)\n",
    "        X = Dropout(0.2)(X)\n",
    "\n",
    "        X = Dense(units=128, activation='relu')(X)\n",
    "        X = BatchNormalization()(X)\n",
    "        X = Dropout(0.2)(X)\n",
    "\n",
    "        X = Dense(units=4, activation='softmax', name=final_model_name)(X)\n",
    "        print(f\"(✔) Successfully attached the classification layers....\")\n",
    "    except:\n",
    "        print(f'(X) Error while attaching the classification layers....')\n",
    "        return None\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca19b169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(✔) Model with name of 'MSE_MSLE_model001.h5' is Successfuly Loaded....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mostafa\\anaconda3\\envs\\capstone\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "resized_model = load_encoder_model(sa_model_path,inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff505fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(✔) Successfully loaded the pretrained model for transfer learning and combine with the Scale Adaptive model.....\n"
     ]
    }
   ],
   "source": [
    "resized_pretrained_model = build_feature_extractor_model(inputs= resized_model[:,:,:,12:] , pretrained_model= pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "599b4946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(✔) Successfully attached the classification layers....\n"
     ]
    }
   ],
   "source": [
    "resized_pretrained_classification_model = attach_classifier(inputs= resized_pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05cb687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = tf.keras.Model(inputs=inputs, outputs = resized_pretrained_classification_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd63bcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 448, 448, 3)]     0         \n",
      "                                                                 \n",
      " req_dim_model (Functional)  (None, 224, 224, 15)      6214      \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " Final_model (Dense)         (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,811,338\n",
      "Trainable params: 24,750,212\n",
      "Non-trainable params: 61,126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0806857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
